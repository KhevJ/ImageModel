{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def process_tif(path, label):\n",
    "#     img = Image.open(path.numpy()).convert('RGB')\n",
    "#     img = img.resize((256, 256))   # Resize image\n",
    "#     # img =  tf.cast(img, tf.float32) / 255.\n",
    "#     img = tf.convert_to_tensor(img, dtype=tf.float32)  # Convert to tensor\n",
    "#     img = img / 255.0  # Normalize to [0, 1]\n",
    "   \n",
    "#     return img, label\n",
    "\n",
    "\n",
    "dataset_path = \"/Users/khevinjugessur/Documents/ENEL525/Project/pngImages\"\n",
    "image_paths = []\n",
    "labels = []\n",
    "class_names = sorted(os.listdir(dataset_path))  \n",
    "\n",
    "# count = 3\n",
    "for class_id, class_name in enumerate(class_names):\n",
    "    # if count == 0: break\n",
    "    # count -= 1\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    counter = 50\n",
    "    for filename in os.listdir(class_folder):\n",
    "        if counter == 0 : break\n",
    "        counter -= 1\n",
    "        image_paths.append(os.path.join(class_folder, filename))\n",
    "        labels.append(class_id)\n",
    "\n",
    "\n",
    "\n",
    "# def preprocess(path, label):\n",
    "#     img, label = tf.py_function(func=process_tif, inp=[path, label], Tout=(tf.float32, tf.int32))\n",
    "#     img.set_shape((256, 256, 3)) \n",
    "#     label.set_shape([])\n",
    "#     return img, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 735\n",
      "Validation dataset size: 157\n",
      "Test dataset size: 158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def preprocess(path, label):\n",
    "    # Decode and resize image\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)  # Decode PNG images (use tf.image.decode_png instead of decode_image)\n",
    "    img = tf.image.resize(img, [256, 256])       # Resize to target size\n",
    "    img = img / 255.0                            # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "\n",
    "\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: validation (15%) and test (15%) from the temp set\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "# Note: test_size=0.5 here splits the remaining 30% equally into 15% for val and 15% for test.\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(train_paths)}\")\n",
    "print(f\"Validation dataset size: {len(val_paths)}\")\n",
    "print(f\"Test dataset size: {len(test_paths)}\")\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#     tf.keras.layers.RandomRotation(0.2)\n",
    "# ])\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.4),\n",
    "])\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "train_ds = train_ds.map(preprocess).map(lambda x, y: (data_augmentation(x), y)).batch(32).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess).batch(32).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess).batch(32).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def display_image(image, label):\n",
    "    plt.imshow(image.numpy())  \n",
    "    plt.title(f\"Label: {class_names[label.numpy()]}\") \n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "    \n",
    "print(len(train_ds))\n",
    "\n",
    "# for image,label in val_ds.take(1):\n",
    "#     for i in range(5):\n",
    "#         display_image(image[i], label[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# def CNN(input_shape=(256, 256, 3), num_classes=21):\n",
    "#     inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "\n",
    "#     # Block 1\n",
    "#     x = layers.Conv2D(8, kernel_size=(7, 7), strides=3, padding='valid')(inputs)  \n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(x) \n",
    "\n",
    "#     # Block 2\n",
    "#     x = layers.Conv2D( 16, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "    \n",
    "#     # Block 3\n",
    "#     x = layers.Conv2D( 32, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "    \n",
    "\n",
    "   \n",
    "#     # Block 4\n",
    "#     x = layers.Conv2D( 64, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(x) \n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "#     # Block 5\n",
    "#     x = layers.Conv2D( 128, kernel_size=(3, 3), strides=2, padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "\n",
    "#     # Flatten\n",
    "#     x = layers.Flatten()(x)  # 61504 features\n",
    "\n",
    "#     x = layers.Dense(64)(x)  \n",
    "    \n",
    "#     x = layers.Dense(21)(x) \n",
    "#     # Fully Connected Layer\n",
    "\n",
    "\n",
    "#     # Softmax Activation\n",
    "#     x = layers.Softmax(axis=-1)(x)  \n",
    "#     outputs = layers.BatchNormalization()(x)\n",
    "\n",
    "#     # Create model\n",
    "#     model = models.Model(inputs, outputs, name=\"CNN\")\n",
    "#     return model\n",
    "\n",
    "# # Create the model\n",
    "# model = CNN()\n",
    "# # from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# # # # Compute class weights\n",
    "# # class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# # class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "\n",
    "# # Compile the model\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],)\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=20,\n",
    "#     validation_data= val_ds,\n",
    "    \n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Display the model architecture\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, Model\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "# # Input layer\n",
    "\n",
    "# inputs = layers.Input(shape=(256, 256, 3))\n",
    "# x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "# x = layers.Dropout(0.5)(x)  # Dropout to reduce overfitting\n",
    "# outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "# # Create the model\n",
    "# model = Model(inputs, outputs)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(\n",
    "#     optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=20,\n",
    "    \n",
    "# )\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"Model evaluation on validation set:\")\n",
    "# model.evaluate(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "# # Input layer\n",
    "# inputnode = tf.keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "# # Convolutional and pooling layers\n",
    "# conv0 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputnode)\n",
    "# conv0 = BatchNormalization()(conv0)\n",
    "# pool0 = MaxPool2D((2, 2))(conv0)\n",
    "\n",
    "# conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(pool0)\n",
    "# conv1 = BatchNormalization()(conv1)\n",
    "# pool1 = MaxPool2D((2, 2))(conv1)\n",
    "\n",
    "# conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(pool1)\n",
    "# conv2 = BatchNormalization()(conv2)\n",
    "# pool2 = MaxPool2D((2, 2))(conv2)\n",
    "\n",
    "# # Flatten and Dense layers\n",
    "# flatten = Flatten()(pool2)\n",
    "# dense1 = Dense(256, activation='relu')(flatten)\n",
    "# dropout1 = Dropout(0.5)(dense1)\n",
    "# x = layers.Dense(128, activation='relu')(dropout1)  \n",
    "# x = Dropout(0.5)(x)  \n",
    "# x = layers.Dense(64, activation='relu')(dropout1)  \n",
    "# x = Dropout(0.5)(x)  \n",
    "\n",
    "\n",
    "# # Output layer\n",
    "# outputnode = Dense(21, activation='softmax')(dropout1)\n",
    "\n",
    "# # Model definition\n",
    "# model = tf.keras.Model(inputs=inputnode, outputs=outputnode)\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.0001,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True\n",
    "# )\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(train_ds, validation_data=val_ds, epochs=25)\n",
    "\n",
    "# # Optional: Viewing the feature map (how the CNN understands images)\n",
    "# conv_output = model.get_layer('conv2d_9').output\n",
    "# conv_model = tf.keras.Model(inputs=model.input, outputs=conv_output)\n",
    "\n",
    "# # Predict the feature map\n",
    "# featuremap = conv_model.predict(test_ds)\n",
    "\n",
    "# # Plot the feature map\n",
    "# plt.imshow(featuremap[0, :, :, 0])  # Display the first feature map\n",
    "# plt.show()\n",
    "\n",
    "# print(featuremap.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted class counts in val_ds: {0: 8, 1: 8, 2: 7, 3: 8, 4: 7, 5: 8, 6: 7, 7: 7, 8: 8, 9: 7, 10: 7, 11: 8, 12: 7, 13: 7, 14: 7, 15: 8, 16: 8, 17: 8, 18: 8, 19: 7, 20: 7}\n",
      "Sorted class counts in val_ds: {0: 43, 1: 43, 2: 42, 3: 43, 4: 42, 5: 43, 6: 42, 7: 42, 8: 43, 9: 42, 10: 42, 11: 43, 12: 42, 13: 42, 14: 42, 15: 43, 16: 43, 17: 43, 18: 43, 19: 42, 20: 42}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Initialize a counter for class labels\n",
    "label_counts = collections.Counter()\n",
    "\n",
    "# Iterate through val_ds and count the labels\n",
    "for _, labels in val_ds.unbatch():  # unbatch() to access individual elements\n",
    "    label_counts[int(labels.numpy())] += 1\n",
    "\n",
    "sorted_label_counts = dict(sorted(label_counts.items()))\n",
    "\n",
    "# Print sorted class counts\n",
    "print(\"Sorted class counts in val_ds:\", sorted_label_counts)\n",
    "\n",
    "\n",
    "# Iterate through val_ds and count the labels\n",
    "for _, labels in train_ds.unbatch():  # unbatch() to access individual elements\n",
    "    label_counts[int(labels.numpy())] += 1\n",
    "\n",
    "sorted_label_counts = dict(sorted(label_counts.items()))\n",
    "\n",
    "# Print sorted class counts\n",
    "print(\"Sorted class counts in val_ds:\", sorted_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.0461 - loss: 19.2951 - val_accuracy: 0.0510 - val_loss: 3.0394 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.0691 - loss: 2.9882 - val_accuracy: 0.0637 - val_loss: 2.9621 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.1603 - loss: 2.6843 - val_accuracy: 0.1019 - val_loss: 3.0701 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.3999 - loss: 2.0417 - val_accuracy: 0.0955 - val_loss: 3.2625 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5797 - loss: 1.5840 - val_accuracy: 0.0955 - val_loss: 3.2355 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7641 - loss: 0.9329 - val_accuracy: 0.1401 - val_loss: 5.2020 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8874 - loss: 0.5845\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8883 - loss: 0.5810 - val_accuracy: 0.1911 - val_loss: 4.5549 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.9298 - loss: 0.3049 - val_accuracy: 0.2229 - val_loss: 5.0233 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.9674 - loss: 0.1957 - val_accuracy: 0.2102 - val_loss: 4.7843 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.9781 - loss: 0.0921 - val_accuracy: 0.2038 - val_loss: 5.4678 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.9865 - loss: 0.0566 - val_accuracy: 0.2102 - val_loss: 6.3069 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9919 - loss: 0.0256\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0253 - val_accuracy: 0.1911 - val_loss: 5.5840 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.1783 - val_loss: 5.5477 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.1911 - val_loss: 5.5721 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0119 - val_accuracy: 0.2038 - val_loss: 5.8338 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0117 - val_accuracy: 0.1911 - val_loss: 5.6551 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9980 - loss: 0.0072\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.1911 - val_loss: 5.7906 - learning_rate: 2.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.1911 - val_loss: 5.8381 - learning_rate: 1.2500e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.1783 - val_loss: 5.8847 - learning_rate: 1.2500e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.1720 - val_loss: 5.8975 - learning_rate: 1.2500e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.1490 - loss: 6.2671\n",
      "Test Loss: 6.066964626312256, Test Accuracy: 0.16455696523189545\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "# Model definition\n",
    "# inputnode = tf.keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "# conv0 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputnode)\n",
    "# conv0 = BatchNormalization()(conv0)\n",
    "# pool0 = MaxPool2D((2, 2))(conv0)\n",
    "\n",
    "# conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool0)\n",
    "# conv1 = BatchNormalization()(conv1)\n",
    "# pool1 = MaxPool2D((2, 2))(conv1)\n",
    "\n",
    "# conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool1)\n",
    "# conv2 = BatchNormalization()(conv2)\n",
    "# pool2 = MaxPool2D((2, 2))(conv2)\n",
    "# # dropout1 = Dropout(0.4)(pool2)\n",
    "\n",
    "# flatten = Flatten()(pool2)\n",
    "# dense1 = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(flatten)\n",
    "# dropout1 = Dropout(0.5)(dense1)\n",
    "\n",
    "# outputnode = Dense(21, activation='softmax')(dropout1)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "# # Input layer\n",
    "# inputnode = tf.keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "# # Convolutional Block 1\n",
    "# conv0 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputnode)\n",
    "# conv0 = BatchNormalization()(conv0)\n",
    "# pool0 = MaxPool2D((2, 2))(conv0)\n",
    "\n",
    "# # Convolutional Block 2\n",
    "# conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool0)\n",
    "# conv1 = BatchNormalization()(conv1)\n",
    "# pool1 = MaxPool2D((2, 2))(conv1)\n",
    "\n",
    "# # Convolutional Block 3\n",
    "# conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool1)\n",
    "# conv2 = BatchNormalization()(conv2)\n",
    "# pool2 = MaxPool2D((2, 2))(conv2)\n",
    "\n",
    "# # Convolutional Block 4 (NEW)\n",
    "# conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool2)\n",
    "# conv3 = BatchNormalization()(conv3)\n",
    "# pool3 = MaxPool2D((2, 2))(conv3)\n",
    "\n",
    "# # Dropout after final pooling layer (optional)\n",
    "# dropout_conv = Dropout(0.4)(pool3)\n",
    "\n",
    "# # Flatten layer\n",
    "# flatten = Flatten()(dropout_conv)\n",
    "\n",
    "# # Fully Connected Block 1\n",
    "# dense1 = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(flatten)\n",
    "\n",
    "\n",
    "# # Fully Connected Block 2 (NEW)\n",
    "# dense2 = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(dense1)\n",
    "\n",
    "\n",
    "# # Fully Connected Block 3 (NEW)\n",
    "# dense3 = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(dense2)\n",
    "# dropout3 = Dropout(0.5)(dense3)\n",
    "\n",
    "# # Output layer\n",
    "# outputnode = Dense(21)(dropout3)\n",
    "\n",
    "#from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# # Load ResNet50\n",
    "# base_model = ResNet50(weights='/Users/khevinjugessur/Documents/ENEL525/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(256, 256, 3))\n",
    "# base_model.trainable = False  # Freeze weights\n",
    "\n",
    "# # Add custom layers\n",
    "# inputnode = tf.keras.Input(shape=(256, 256, 3))\n",
    "# x = base_model(inputnode, training=False)\n",
    "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# outputnode = tf.keras.layers.Dense(21, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs=inputnode, outputs=outputnode)\n",
    "\n",
    "# Learning rate schedule and optimizer\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "             loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # \n",
    "\n",
    "# Callbacks\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=20, callbacks=[ lr_callback])\n",
    "\n",
    "# Test performance\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input layer\n",
    "# inputnode = tf.keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "# # Convolutional and pooling layers\n",
    "# conv0 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputnode)\n",
    "# conv0 = BatchNormalization()(conv0)\n",
    "# pool0 = MaxPool2D((2, 2))(conv0)\n",
    "\n",
    "# conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool0)\n",
    "# conv1 = BatchNormalization()(conv1)\n",
    "# pool1 = MaxPool2D((2, 2))(conv1)\n",
    "\n",
    "# conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.02))(pool1)\n",
    "# conv2 = BatchNormalization()(conv2)\n",
    "# pool2 = MaxPool2D((2, 2))(conv2)\n",
    "\n",
    "# # Flatten and Dense layers\n",
    "# flatten = Flatten()(pool2)\n",
    "# dense1 = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(flatten)\n",
    "# dropout1 = Dropout(0.5)(dense1)\n",
    "# outputnode = Dense(21, activation='softmax')(dropout1)\n",
    "\n",
    "# # Model definition\n",
    "# model = tf.keras.Model(inputs=inputnode, outputs=outputnode)\n",
    "\n",
    "# # Learning rate schedule with ReduceLROnPlateau\n",
    "# lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor=\"val_loss\", factor=0.5, patience=3, verbose=1\n",
    "# )\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "# )\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[lr_callback, early_stopping])\n",
    "\n",
    "# # Optional: Class weights for imbalanced datasets\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import numpy as np\n",
    "\n",
    "# class_weights = compute_class_weight(\n",
    "#     'balanced', classes=np.unique(train_labels), y=train_labels\n",
    "# )\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[lr_callback, early_stopping], class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "# base_model = ResNet50(\n",
    "#     input_shape=(256, 256, 3),  \n",
    "#     include_top=False,         \n",
    "#     weights=\"/Users/khevinjugessur/Documents/ENEL525/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"       # Load pre-trained ImageNet weights\n",
    "# )\n",
    "\n",
    "# # Freeze all layers initially\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "\n",
    "\n",
    "# # Add classification layers\n",
    "\n",
    "# x = base_model.output\n",
    "# x = layers.GlobalAveragePooling2D()(x) \n",
    "# x = layers.Dense(128, activation='relu')(x)  \n",
    "# x = layers.Dropout(0.5)(x)                   \n",
    "# outputs = layers.Dense(21, activation='softmax')(x)  \n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=10\n",
    "# )\n",
    "\n",
    "\n",
    "# # Unfreeze top N layers (e.g., last 20 layers)\n",
    "# for layer in base_model.layers[-20:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history_fine_tune = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=20\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000000</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">693</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000000\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m64,000,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │           \u001b[38;5;34m693\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,066,689</span> (732.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m192,066,689\u001b[0m (732.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,022,229</span> (244.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,022,229\u001b[0m (244.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,044,460</span> (488.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m128,044,460\u001b[0m (488.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQJ0lEQVR4nO3dd3gU5f428Ht3s9n03guEJPQSIEAEpEkggCJ4UBALoKhHD/gTEV/kKE0UOIocFBE8SkCOBdBjB2lBEAKI0qQGAiEJgXTSy2525/1jkk2W1A1JZsv9ua65YGdnZ7+TSbJ3nnmeZ2SCIAggIiIikohc6gKIiIjIujGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkrKRuoCm0Ol0uHnzJpydnSGTyaQuh4iIiJpAEAQUFhYiICAAcnn97R9mEUZu3ryJ4OBgqcsgIiKiZkhNTUVQUFC9z5tFGHF2dgYgHoyLi4vE1RAREVFTFBQUIDg4WP85Xh+zCCNVl2ZcXFwYRoiIiMxMY10s2IGViIiIJMUwQkRERJJiGCEiIiJJmUWfkabQarXQaDRSl0EWQqFQwMbGhkPJiYjagEWEkaKiIty4cQOCIEhdClkQBwcH+Pv7w9bWVupSiIgsmtmHEa1Wixs3bsDBwQHe3t78S5bumiAIUKvVyMrKQlJSEjp27NjgZD1ERHR3zD6MaDQaCIIAb29v2NvbS10OWQh7e3solUokJydDrVbDzs5O6pKIiCyWxfy5xxYRamlsDSEiahv8bUtERESSMjqM/Pbbbxg/fjwCAgIgk8nw/fffN/qaAwcOoG/fvlCpVAgPD8fmzZubUSo1JiQkBGvWrJG6DCIiIqMYHUaKi4sRERGBdevWNWn7pKQk3H///RgxYgROnz6NOXPm4JlnnsHu3buNLtZSyGSyBpclS5Y0a79//PEHnnvuuRap8auvvoJCocCsWbNaZH9ERET1kQl3MR5WJpPhu+++w8SJE+vdZv78+dixYwfOnTunX/foo48iLy8Pu3btatL7FBQUwNXVFfn5+bXuTVNWVoakpCR06NDBbDoZpqen6/+/bds2LFq0CAkJCfp1Tk5OcHJyAiCO7NBqtbCxadu+xtHR0ejfvz8+/vhj3Lx5U9KvrVqtlmR4rTl+bxERmZKGPr9ravVPuKNHjyI6OtpgXUxMDObMmVPva8rLy1FeXq5/XFBQ0FrlScLPz0//f1dXV8hkMv26AwcOYMSIEdi5cyfeeOMNnD17Fnv27EFwcDDmzp2LY8eOobi4GF27dsWKFSsMvrYhISGYM2eO/msrk8nwySefYMeOHdi9ezcCAwPx3nvv4cEHH2ywvqSkJBw5cgT/+9//8Ouvv+Lbb7/FY489ZrBNbGws3nvvPSQmJsLDwwOTJk3Chx9+CADIy8vD/Pnz8f333yM/Px/h4eFYuXIlHnjgASxZsgTff/89Tp8+rd/XmjVrsGbNGly/fh0AMGPGDOTl5aF///5Yt24dVCoVkpKS8N///hfvv/8+EhIS4OjoiPvuuw9r1qyBj4+Pfl/nz5/H/Pnz8dtvv0EQBPTu3RubN29GWloaRo4cidTUVIOv/5w5c3DixAkcOnSo6SeQqA6CIKBYrUVhmQYFpRXivwb/r0BBmQaaCgFKhQw2Chls5HIoFTIoFXLYKMT/G66r/VipkMNGLv6rXyevfk7Ovvx1EgDodAI0OgEVWh00WgEVOh00FQI0Oh0qtJXr9c/X2EYroEIrVK7ToeLOfVQ+L8C857p6enAHBHs4SPLerR5G0tPT4evra7DO19cXBQUFKC0trXM47ooVK7B06dJmvZ8gCCjVaJv12rtlr1S02Kie1157DatWrUJoaCjc3d2RmpqKcePG4e2334ZKpcKWLVswfvx4JCQkoF27dvXuZ+nSpXjnnXfw7rvvYu3atXj88ceRnJwMDw+Pel+zadMm3H///XB1dcUTTzyBjRs3GoSR9evXY+7cuVi5ciXGjh2L/Px8xMfHAwB0Oh3Gjh2LwsJCfP755wgLC8OFCxegUCiMOv64uDi4uLhg7969+nUajQbLli1D586dkZmZiblz52LGjBnYuXMnACAtLQ1Dhw7F8OHDsX//fri4uCA+Ph4VFRUYOnQoQkND8d///hevvvqqfn9ffPEF3nnnHaNqI8tUodWhsKwChZWhoaC0OkAUlGr06wvLKiqfM1xXWFYBrc68P4zIuo2PCLDcMNIcCxYswNy5c/WPCwoKEBwc3KTXlmq06LZImv4oF96MgYNty3xJ33zzTYwaNUr/2MPDAxEREfrHy5Ytw3fffYcff/wRs2fPrnc/M2bMwNSpUwEAy5cvxwcffIDjx49jzJgxdW6v0+mwefNmrF27FoB4Se2VV17RX64AgLfeeguvvPIKXnrpJf3r+vfvDwDYt28fjh8/josXL6JTp04AgNDQUKOP39HREZ9++qnB5Zmnn35a///Q0FB88MEH6N+/P4qKiuDk5IR169bB1dUVW7duhVKpBAB9DQAwc+ZMbNq0SR9GfvrpJ5SVlWHy5MlG10emRRAElGl0lcFAg/yarREGQeKOlooaz5WoW+aPGBu5DC72Sjjb2cDFTgkXexs4qyr/tVPC1kau/6taoxX/Itf/Za7TQV0h/lv1l3iFTqj+K93gseE2FVoBaq2uRY7BUsllEFug5DJ9S9SdrUs2cjmUNlXbVLdE2SjksL2jtarqeaVCDoVcZvatUr4u0l2ObvUw4ufnh4yMDIN1GRkZcHFxqXeSMpVKBZVK1dqlmbR+/foZPC4qKsKSJUuwY8cO3Lp1CxUVFSgtLUVKSkqD++nVq5f+/46OjnBxcUFmZma92+/duxfFxcUYN24cAMDLywujRo1CbGwsli1bhszMTNy8eRMjR46s8/WnT59GUFCQQQhojp49e9bqJ3LixAksWbIEZ86cwe3bt6HTib94U1JS0K1bN5w+fRpDhgzRB5E7zZgxA2+88QaOHTuGe+65B5s3b8bkyZPh6Oh4V7VSyyqv0OJ2sQY5xeXILVYbLDnFatwuVte6/FFYpoFG2zKtEg62CrjYVYaJO0OFnbLO51xrPGenlHPeIyIjtXoYGThwoL4ZvcrevXsxcODAVnk/e6UCF96MaZV9N+W9W8qdH5Dz5s3D3r17sWrVKoSHh8Pe3h4PP/ww1Gp1g/u584NZJpPpP8TrsnHjRuTm5hoERZ1Oh7/++gtLly5tdJbbxp6Xy+W17iFU1w0O7zz+4uJixMTEICYmBl988QW8vb2RkpKCmJgY/degsff28fHB+PHjsWnTJnTo0AG//PILDhw40OBr6O5U9aPILVI3GC5yaqwrKq9o9vvJZTAICdVB4o519mJwcLkjVDjZ2UCp4PRLRG3N6DBSVFSExMRE/eOkpCScPn0aHh4eaNeuHRYsWIC0tDRs2bIFAPD888/jww8/xP/7f/8PTz/9NPbv34/t27djx44dLXcUNchksha7VGJK4uPjMWPGDDz00EMAxPNQ1eGzpeTk5OCHH37A1q1b0b17d/16rVaLe++9F3v27MGYMWMQEhKCuLg4jBgxotY+evXqhRs3buDy5ct1to54e3sjPT0dgiDo/3qs2Zm1PpcuXUJOTg5Wrlypv2T3559/1nrvzz77DBqNpt7WkWeeeQZTp05FUFAQwsLCMHjw4EbfmxpWUKZBYmYREjOKcCWzEFezipGeXyaGixI11BXGXzpQyGVwd7CFp6MtPOpYXO3FlgoxXFS3Wjjatly/LSJqO0Z/av/5558GH0JVfTumT5+OzZs349atWwaXDjp06IAdO3bg5Zdfxvvvv4+goCB8+umniImRpvXCXHXs2BHffvstxo8fD5lMhoULFzbYwtEc//3vf+Hp6YnJkyfX+oU+btw4bNy4EWPGjMGSJUvw/PPPw8fHR99ZNT4+Hi+++CKGDRuGoUOHYtKkSVi9ejXCw8Nx6dIlyGQyjBkzBsOHD0dWVhbeeecdPPzww9i1axd++eWXBod8AUC7du1ga2uLtWvX4vnnn8e5c+ewbNkyg21mz56NtWvX4tFHH8WCBQvg6uqKY8eOYcCAAejcuTMAcSSXi4sL3nrrLbz55pst+vWzdDlF5biSWSQGj0wxeCRmFiGjoLzR19op5fB0VMHD0RbujnWHDE/9vyo429lAbu4X4ImoyYwOI8OHD6/VzF5TXbOrDh8+HKdOnTL2raiG1atX4+mnn8agQYPg5eWF+fPnt/iQ59jYWDz00EN1/mU5adIkPPnkk8jOzsb06dNRVlaGf//735g3bx68vLzw8MMP67f93//+h3nz5mHq1KkoLi7WD+0FgK5du+Kjjz7C8uXLsWzZMkyaNAnz5s3Df/7znwZr8/b2xubNm/HPf/4TH3zwAfr27YtVq1YZDFP29PTE/v378eqrr2LYsGFQKBTo3bu3QeuHXC7HjBkzsHz5ckybNu1uv2QWRxAEpBeUiWEjowiJWdUtHrdLal9Oq+LnYodwHyf9EuhuD09HW7F1w8nWIlsriajl3NWkZ23F0iY9I2nNnDkTWVlZ+PHHHxvczpK/t3Q6ATdul+pbN2q2eNTXZ0MmA4Lc7dHRx1kfOjr6OCHMxwkudnVfFiMi62Yyk54RmYr8/HycPXsWX375ZaNBxBIJgoDfk3Lx8cGrOHotB2Waui/zKeQyhHg6VIaN6uAR5u0Ee9uW66RNRFSFYYSsxoQJE3D8+HE8//zzBnO4WDqdTsCeCxnYcPAqTqfm6dfb2sgR6uWIjr7OCPd2QkdfsaWjvacjbG04ooSI2g7DCFkNaxvGq67Q4fvTafj44FVczSoGIAaQyf2C8OQ9IQj3cYKCnUSJyAQwjBBZmKLyCmw9noJPDyUhvaAMAOBsZ4NpA9tjxqAO8Ha27gkFicj0MIwQWYjsonJ8duQ6PjtyHQVlYidUH2cVnhnSAVMHtIMzO5kSkYliGCEyc6m5Jfjk0DVs+yMV5ZUTjIV6OeLvw0IxsU8gVDbsdEpEpo1hhMhMXbxVgA0Hr+Lnv27p7xYbEeSKF4aHYVQ3P/YHISKzwTBCZEaqhuduOHgVBxKy9OuHdPTCC8PDMDDUk9OhE5HZYRghMgM6nYC9F8XhuadS8gCIN4Ub19Mfzw8LQ49AV2kLJCK6CwwjZmz48OHo3bs31qxZI3Up1ErqG577SGQQnhsaivaejo3sgYjI9DGMSGD8+PHQaDTYtWtXrecOHTqEoUOH4syZM+jVq1eLvF9paSkCAwMhl8uRlpYGlYpDO01dfcNzn7ynPZ4azOG5RGRZGEYkMHPmTEyaNAk3btxAUFCQwXObNm1Cv379WiyIAOKN67p37w5BEPD9999jypQpLbZvYwmCAK1WCxsbfuvVpbi8ArGHk/Dp4STkl4o3pvNxVmHmvR3wWBSH5xKRZeKczxJ44IEH9HehramoqAhff/01Zs6ciZycHEydOhWBgYFwcHBAz5498dVXXzXr/TZu3IgnnngCTzzxBDZu3Fjr+fPnz+OBBx6Ai4sLnJ2dMWTIEFy9elX/fGxsLLp37w6VSgV/f3/Mnj0bAHD9+nXIZDKcPn1av21eXh5kMpl+ttMDBw5AJpPhl19+QWRkJFQqFQ4fPoyrV69iwoQJ8PX1hZOTE/r37499+/YZ1FVeXo758+cjODgYKpUK4eHh2LhxIwRBQHh4OFatWmWw/enTpyGTyZCYmNisr5OUyiu02BSfhGHv/or39l5GfqkGoV6OWPm3njg0fwT+PiyMQYSILJbl/XkqCICmRJr3VjqItzZthI2NDaZNm4bNmzfj9ddf149++Prrr6HVajF16lQUFRUhMjIS8+fPh4uLC3bs2IEnn3wSYWFhGDBgQJNLunr1Ko4ePYpvv/0WgiDg5ZdfRnJyMtq3bw8ASEtLw9ChQzF8+HDs378fLi4uiI+PR0WFOGnW+vXrMXfuXKxcuRJjx45Ffn4+4uPjjf7SvPbaa1i1ahVCQ0Ph7u6O1NRUjBs3Dm+//TZUKhW2bNmC8ePHIyEhAe3atQMATJs2DUePHsUHH3yAiIgIJCUlITs7GzKZDE8//TQ2bdqEefPm6d9j06ZNGDp0KMLDw42uTypanYBvT97Amn1XkJZXCgBo7+mAuaM64YFeARyeS0RWwfLCiKYEWB4gzXv/8yZg27QOhU8//TTeffddHDx4EMOHDwcgfphOmjQJrq6ucHV1NfigffHFF7F7925s377dqDASGxuLsWPHwt3dHQAQExODTZs2YcmSJQCAdevWwdXVFVu3boVSKf7l3alTJ/3r33rrLbzyyit46aWX9Ov69+/f5Pev8uabbxrcnM7DwwMRERH6x8uWLcN3332HH3/8EbNnz8bly5exfft27N27F9HR0QCA0NBQ/fYzZszAokWLcPz4cQwYMAAajQZffvllrdYSUyUIAnafT8eqPZeRmFkEAPB1UeH/RnbE5H7BUCrYaElE1oO/8STSpUsXDBo0CLGxsQCAxMREHDp0CDNnzgQAaLVaLFu2DD179oSHhwecnJywe/dupKSkNPk9tFotPvvsMzzxxBP6dU888QQ2b94MnU6cqfP06dMYMmSIPojUlJmZiZs3b2LkyJF3c6gAgH79+hk8Lioqwrx589C1a1e4ubnByckJFy9e1B/f6dOnoVAoMGzYsDr3FxAQgPvvv1//9fvpp59QXl6ORx555K5rbW3xidmYuC4ez39+EomZRXC1V2LB2C44+OoIPB7VnkGEiKyO5bWMKB3EFgqp3tsIM2fOxIsvvoh169Zh06ZNCAsL03/4vvvuu3j//fexZs0a9OzZE46OjpgzZw7UanWT9797926kpaXV6rCq1WoRFxeHUaNGwd7evt7XN/QcAMjl4oemIAj6dRqNps5tHR0NW4zmzZuHvXv3YtWqVQgPD4e9vT0efvhh/fE19t4A8Mwzz+DJJ5/Ev//9b2zatAlTpkyBg4Nx56AtnU7Nw7u7LyE+MQcA4GCrwMx7O+DZoaFwYX8QIrJilhdGZLImXyqR2uTJk/HSSy/hyy+/xJYtW/DCCy/o+4/Ex8djwoQJ+lYNnU6Hy5cvo1u3bk3e/8aNG/Hoo4/i9ddfN1j/9ttvY+PGjRg1ahR69eqFzz77DBqNplbriLOzM0JCQhAXF4cRI0bU2r+3tzcA4NatW+jTpw8AGHRmbUh8fDxmzJiBhx56CIDYUnL9+nX98z179oROp8PBgwf1l2nuNG7cODg6OmL9+vXYtWsXfvvttya9d1u7klGIVXsSsPt8BgDAViHHY1HtMGtEOIfoEhHBEsOIGXFycsKUKVOwYMECFBQUYMaMGfrnOnbsiG+++QZHjhyBu7s7Vq9ejYyMjCaHkaysLPz000/48ccf0aNHD4Pnpk2bhoceegi5ubmYPXs21q5di0cffRQLFiyAq6srjh07hgEDBqBz585YsmQJnn/+efj4+GDs2LEoLCxEfHw8XnzxRdjb2+Oee+7BypUr0aFDB2RmZuKNN95oUn0dO3bEt99+i/Hjx0Mmk2HhwoX6S0cAEBISgunTp+Ppp5/Wd2BNTk5GZmYmJk+eDABQKBSYMWMGFixYgI4dO2LgwIFNeu+2kppbgjX7ruC7UzegE8QZU//WNwhzojsiyN10W3CIiNoaL05LbObMmbh9+zZiYmIQEFDd8faNN95A3759ERMTg+HDh8PPzw8TJ05s8n63bNkCR0fHOvt7jBw5Evb29vj888/h6emJ/fv3o6ioCMOGDUNkZCQ++eQTfSvJ9OnTsWbNGnz00Ufo3r07HnjgAVy5ckW/r9jYWFRUVCAyMhJz5szBW2+91aT6Vq9eDXd3dwwaNAjjx49HTEwM+vbta7DN+vXr8fDDD+Mf//gHunTpgmeffRbFxcUG28ycORNqtRpPPfVUk782rS2rsBxLfjyP+947gP+dFINITHdf7J4zFKseiWAQISK6g0yoecHfRBUUFMDV1RX5+flwcXExeK6srAxJSUno0KED7OzsJKqQpHLo0CGMHDkSqamp8PX1bdF9G/u9VVCmwX8OXkNsfBJK1FoAwOBwT7wa0wW9g91atDYiInPQ0Od3TbxMQ2apvLwcWVlZWLJkCR555JEWDyLGKFVr8dnR61h/4Kp+1tSIIFf8vzFdMDjcS7K6iIjMBcMImaWvvvoKM2fORO/evbFlyxZJatBoddj+Zyo+iLuCjIJyAEC4jxPmje6MmO6++s7IRETUMIYRMkszZsww6PDblgRBwM9/3cJ7exJwPUec7TfQzR4vj+qEh/oEctZUIiIjMYwQGek/v13Dil8uAQC8nGwxe0Q4pka1g8pGIXFlRETmiWGEyAjHk3Lxzu4EAMDfh4Xi/+7rCEcVf4yIiO6GxfwWNYNBQWRm7vyeyi4qx4tfnYRWJ2Bi7wC8NqYL+4UQEbUAs59nRKEQm8aNmSadqClKSsT+IEqlElqdgDlbTyOjoBxh3o54+6GeDCJERC3E7FtGbGxs4ODggKysLCiVSv39UoiaSxAElJSUIDMzE25ublAoFHh/3xUcTsyGnVKO9U9E8tIMEVELMvvfqDKZDP7+/khKSkJycrLU5ZAFcXNzg5+fH+ITs7Em7jIA4O2JPdHJ11niyoiILIvZhxEAsLW1RceOHXmphlqMUqmEQqFARkEZXtp6CoIAPNo/GJMig6QujYjI4lhEGAHE29lzOnhqSRVaHV786hSyi9To4ueMJQ92l7okIiKLxA4WRPVYvfcyjiflwkllg48e7ws7JecRISJqDQwjRHX49VImPjpwFQCwclJPhHo7SVwREZHlYhghukNaXile3n4aADB9YHs80CtA2oKIiCwcwwhRDeoKHWZ/eRJ5JRr0CnLFP+/vKnVJREQWj2GEqIZ/7bqEUyl5cLGzwbrH+vJ+M0REbYBhhKjSrnO3sPFwEgDgvcm9EezhIHFFRETWgWGECEByTjFe/fovAMBzQ0MxqpuvxBUREVkPhhGyemUaLf7xxUkUllcgsr07Xo3pLHVJRERWhWGErN6yny/g/M0CuDso8eFjfaBU8MeCiKgt8bcuWbUfTqfhi99TIJMB/57SG/6u9lKXRERkdRhGyGolZhZhwbdnAQCzR4RjeGcfiSsiIrJODCNklUrVWvzjixMoUWsxMNQTc6I7SV0SEZHVYhghq7Twh3O4nFEELycV3p/aGwq5TOqSiIisFsMIWZ3tf6bimxM3IJcBH0ztDR9n3u2ZiEhKDCNkVS7eKsDC788BAOaO6oRBYV4SV0RERAwjZDWKyisw64uTKK/QYWgnb/xjeLjUJRERERhGyEoIgoAF357Ftexi+LnYYc2U3pCznwgRkUlgGCGr8PnvKfjpzE3YyGVY93gfeDjaSl0SERFVYhghi3f2Rj6W/XQBADB/TBdEtveQuCIiIqqJYYQsWn6pBv/48gTUWh1GdfPFM0M6SF0SERHdgWGELJYgCHj16zNIzS1FkLs9Vj0cAZmM/USIiEwNwwhZrI2Hk7DnQgZsFXJ89HhfuDoopS6JiIjqwDBCFulE8m2s/OUSAOCNB7qiV5CbtAUREVG9GEbI4pRptHjxy5Oo0Am4v5c/nrynvdQlERFRAxhGyOL8djkLN/PL4OOswsq/9WQ/ESIiE8cwQhZn1/l0AMD9vfzhbMd+IkREpo5hhCyKRqtD3MVMAEBMdz+JqyEioqZoVhhZt24dQkJCYGdnh6ioKBw/frzB7desWYPOnTvD3t4ewcHBePnll1FWVtasgokacjwpF/mlGng42qJ/CCc3IyIyB0aHkW3btmHu3LlYvHgxTp48iYiICMTExCAzM7PO7b/88ku89tprWLx4MS5evIiNGzdi27Zt+Oc//3nXxRPdadc58RLNqK6+UPDeM0REZsHoMLJ69Wo8++yzeOqpp9CtWzds2LABDg4OiI2NrXP7I0eOYPDgwXjssccQEhKC0aNHY+rUqY22phAZS6cTsOeCGEZievhKXA0RETWVUWFErVbjxIkTiI6Ort6BXI7o6GgcPXq0ztcMGjQIJ06c0IePa9euYefOnRg3bly971NeXo6CggKDhagxZ27kIaOgHE4qGwwK85K6HCIiaiIbYzbOzs6GVquFr6/hX52+vr64dOlSna957LHHkJ2djXvvvReCIKCiogLPP/98g5dpVqxYgaVLlxpTGpF+FM3wzt6wUyokroaIiJqq1UfTHDhwAMuXL8dHH32EkydP4ttvv8WOHTuwbNmyel+zYMEC5Ofn65fU1NTWLpPMnCAI2HM+AwBH0RARmRujWka8vLygUCiQkZFhsD4jIwN+fnV/ACxcuBBPPvkknnnmGQBAz549UVxcjOeeew6vv/465PLaeUilUkGlUhlTGlm5K5lFSMouhq1CjhFdfKQuh4iIjGBUy4itrS0iIyMRFxenX6fT6RAXF4eBAwfW+ZqSkpJagUOhEJvQBUEwtl6iOlWNorm3oxecVEZlbCIikpjRv7Xnzp2L6dOno1+/fhgwYADWrFmD4uJiPPXUUwCAadOmITAwECtWrAAAjB8/HqtXr0afPn0QFRWFxMRELFy4EOPHj9eHEqK7tbuyv0hMd46iISIyN0aHkSlTpiArKwuLFi1Ceno6evfujV27duk7taakpBi0hLzxxhuQyWR44403kJaWBm9vb4wfPx5vv/12yx0FWbXU3BKcv1kAuQyI7sowQkRkbmSCGVwrKSgogKurK/Lz8+Hi4iJ1OWRiPj10DW/tuIioDh7Y9ve6LxcSEVHba+rnN+9NQ2avahTNmB4cRUNEZI4YRsisZRWW44/kXADAaA7pJSIySwwjZNb2XcyAIAA9A10R6GYvdTlERNQMDCNk1qpG0fASDRGR+WIYIbNVUKZBfGI2AA7pJSIyZwwjZLZ+vZQJjVZAqLcjwn2cpS6HiIiaiWGEzJZ+FA07rhIRmTWGETJLZRotfk3IBMAb4xERmTuGETJLh69ko0Sthb+rHXoFuUpdDhER3QWGETJL1fei8YNMJpO4GiIiuhsMI2R2KrQ67Lso9hcZzVE0RERmj2GEzM7x67m4XaKBu4MSA0I8pC6HiIjuEsMImZ3d58RLNNFdfWGj4LcwEZG5429yMiuCIGDPBfESDUfREBFZBoYRMit/3cjHrfwyONgqcG9HL6nLISKiFsAwQmZlV+UomhGdfWCnVEhcDRERtQSGETIrVUN6OYqGiMhyMIyQ2UjMLMS1rGLYKuS4r4uP1OUQEVELYRghs7GrchTNoHBPONspJa6GiIhaCsMImY3dvDEeEZFFYhghs5CWV4qzafmQy4DobuwvQkRkSRhGyCxUTXTWr70HvJxUEldDREQtiWGEzIL+xng9eImGiMjSMIyQycspKscf13MBAKN5iYaIyOIwjJDJ23cxAzoB6B7ggmAPB6nLISKiFsYwQiaPo2iIiCwbwwiZtMIyDQ5fyQbA/iJERJaKYYRM2oGELKi1OoR6OaKjj5PU5RARUStgGCGTVn0vGj/IZDKJqyEiotbAMEImq0yjxa+XMgEAMbwxHhGRxWIYIZN15Go2itVa+LnYISLITepyiIiolTCMkMnafU4cRTO6uy/kcl6iISKyVAwjZJIqtDrsvSiGkRgO6SUismgMI2SS/ky+jdxiNdwclBjQwUPqcoiIqBUxjJBJ2lV5Y7yRXXyhVPDblIjIkvG3PJkcQRCw90LlrKuc6IyIyOIxjJDJOZdWgLS8UjjYKjCko5fU5RARUStjGCGTs+v8LQDAsE7esFMqJK6GiIhaG8MImRz9jfF4iYaIyCowjJBJScwsQmJmEZQKGUZ08ZG6HCIiagMMI2RSqu5FMzDMCy52SomrISKitsAwQiZlT2UYGcOJzoiIrAbDCJmMm3mlOHMjHzIZMKobb4xHRGQtGEbIZFS1ikS2c4e3s0riaoiIqK0wjJDJ4CgaIiLrxDBCJiG3WI3fk3IA8MZ4RETWhmGETMK+ixnQCUA3fxcEezhIXQ4REbUhhhEyCVX9RdgqQkRkfRhGSHJF5RX47Uo2ACCmB0fREBFZG4YRktzBhCyoK3QI8XRAZ19nqcshIqI2xjBCkttd4xKNTCaTuBoiImprDCMkqfIKLfZfygQAjGZ/ESIiq8QwQpI6cjUHReUV8HFWoU+wm9TlEBGRBBhGSFJVo2hGd/eFXM5LNERE1ohhhCSj1QnYUzXrand/iashIiKpMIyQZE4k30ZOsRqu9kpEhXpIXQ4REUmEYYQks+uceIlmZBcfKBX8ViQislb8BCBJCIJQPaSXN8YjIrJqDCMkifM3C5CWVwo7pRxDO3pLXQ4REUmIYYQkUdUqMqyTN+xtFRJXQ0REUmpWGFm3bh1CQkJgZ2eHqKgoHD9+vMHt8/LyMGvWLPj7+0OlUqFTp07YuXNnswom8ycIAnaevQUAGMNLNEREVs/G2Bds27YNc+fOxYYNGxAVFYU1a9YgJiYGCQkJ8PHxqbW9Wq3GqFGj4OPjg2+++QaBgYFITk6Gm5tbS9RPZuhkym1czSqGvVKB6K68MR4RkbUzOoysXr0azz77LJ566ikAwIYNG7Bjxw7Exsbitddeq7V9bGwscnNzceTIESiVSgBASEjI3VVNZm3bH6kAgHE9/eFsp5S4GiIikppRl2nUajVOnDiB6Ojo6h3I5YiOjsbRo0frfM2PP/6IgQMHYtasWfD19UWPHj2wfPlyaLXaet+nvLwcBQUFBgtZhqLyCvz8l3iJZkr/YImrISIiU2BUGMnOzoZWq4Wvr2HTuq+vL9LT0+t8zbVr1/DNN99Aq9Vi586dWLhwId577z289dZb9b7PihUr4Orqql+Cg/mhZSl+PnMTJWotQr0c0T/EXepyiIjIBLT6aBqdTgcfHx/85z//QWRkJKZMmYLXX38dGzZsqPc1CxYsQH5+vn5JTU1t7TKpjWz7UzyXk/sHQybjvWiIiMjIPiNeXl5QKBTIyMgwWJ+RkQE/v7pHRfj7+0OpVEKhqB6+2bVrV6Snp0OtVsPW1rbWa1QqFVQqlTGlkRm4nFGIUyl5UMhl+FvfQKnLISIiE2FUy4itrS0iIyMRFxenX6fT6RAXF4eBAwfW+ZrBgwcjMTEROp1Ov+7y5cvw9/evM4iQ5arquDqyiw98nO0kroaIiEyF0Zdp5s6di08++QSfffYZLl68iBdeeAHFxcX60TXTpk3DggUL9Nu/8MILyM3NxUsvvYTLly9jx44dWL58OWbNmtVyR0EmT12hw3en0gCw4yoRERkyemjvlClTkJWVhUWLFiE9PR29e/fGrl279J1aU1JSIJdXZ5zg4GDs3r0bL7/8Mnr16oXAwEC89NJLmD9/fssdBZm8fRczkFusho+zCsM6cfp3IiKqJhMEQZC6iMYUFBTA1dUV+fn5cHFxkbocaobpscdx8HIWZo0Iw6sxXaQuh4iI2kBTP795bxpqdWl5pfjtShYAYHI/XqIhIiJDDCPU6r758wYEAbgn1APtPR2lLoeIiEwMwwi1Kp1OwPbKuUUe7d9O4mqIiMgUMYxQq4q/mo20vFI429nwDr1ERFQnhhFqVVVzi0zsHQg7paKRrYmIyBoxjFCruV2sxp7z4my9nFuEiIjqwzBCrea7U2lQa3XoHuCCHoGuUpdDREQmimGEWoUgVHdcZasIERE1hGGEWsVfN/JxKb0QKhs5JkTwpnhERFQ/hhFqFVsrO66O7eEHVwelxNUQEZEpYxihFleirsBPZ24CACbzEg0RETWCYYRa3M6z6Sgqr0B7Twfc08FT6nKIiMjEMYxQi9v2RwoA8T40crlM4mqIiMjUMYxQi7qaVYQ/rt+GXAZM6hskdTlERGQGGEaoRVUN5x3R2Qd+rnYSV0NEROaAYYRajEarw/9O3ADAjqtERNR0DCPUYvZfykR2kRpeTirc18VH6nKIiMhMMIxQi9leObfIpMhAKBX81iIioqbhJwa1iPT8MvyakAlAHEVDRETUVAwj1CL+d/IGdALQP8QdYd5OUpdDRERmhGGE7ppOV/OmeO0kroaIiMwNwwjdtWNJOUjOKYGTygbjevpJXQ4REZkZhhG6a1UdV8dHBMDB1kbiaoiIyNwwjNBdyS/R4Jdz6QCARzm3CBERNQPDCN2VH86kobxChy5+zugV5Cp1OUREZIYYRuiubKu8RDO5XzBkMt4Uj4iIjMcwQs12Li0f528WwFYhx0N9AqUuh4iIzBTDCDVb1XDe0d194e5oK3E1RERkrhhGqFnKNFp8dyoNADCFHVeJiOguMIxQs+w6l47CsgoEutljcJiX1OUQEZEZYxihZqnZcVUuZ8dVIiJqPoYRMlpyTjGOXsuBTAY83C9I6nKIiMjMMYyQ0ao6rg7t6I1AN3uJqyEiInPHMEJGqdDq8M2JGwDYcZWIiFoGwwgZ5eDlLGQUlMPD0RbRXX2lLoeIiCwAwwgZparj6kN9AmFrw28fIiK6e/w0oSbLLCzD/kuZAHiJhoiIWg7DCDXZtyfTUKET0KedGzr5OktdDhERWQiGEWoSQRCwvfISzZR+bBUhIqKWwzBCTfJn8m1cyy6Gg60CD0QESF0OERFZEIYRapKtx8VWkQd6+cNJZSNxNUREZEkYRqhRhWUa7Dx7CwA7rhIRUctjGKFG/XTmFko1WoT7OKFvO3epyyEiIgvDMEKN2vZHCgCx46pMxpviERFRy2IYoQZdSi/AmRv5sJHL8FDfQKnLISIiC8QwQg2qmnF1VDdfeDmpJK6GiIgsEcMI1au8QovvTqUBACaz4yoREbUShhGq157zGcgr0cDf1Q5DO3pLXQ4REVkohhGq1/Y/xUs0j0QGQSFnx1UiImodDCNUp9TcEhy6kg0AeITTvxMRUStiGKE6fXtS7CsyONwTwR4OEldDRESWjGGE6rQ/IRMAMCGCw3mJiKh1MYxQLXklavx1Iw8AMLQTO64SEVHrYhihWo5czYEgAB19nODnaid1OUREZOEYRqiWQ1eyAABDOJyXiIjaAMMIGRAEAb9dFkfRDOnoJXE1RERkDRhGyMD1nBKk5ZVCqZAhKtRD6nKIiMgKMIyQgapLNP3ae8DB1kbiaoiIyBowjJCBqks09/ISDRERtRGGEdLTaHU4di0HAHgvGiIiajPNCiPr1q1DSEgI7OzsEBUVhePHjzfpdVu3boVMJsPEiROb87bUyk6n5qGovALuDkp0D3CRuhwiIrISRoeRbdu2Ye7cuVi8eDFOnjyJiIgIxMTEIDMzs8HXXb9+HfPmzcOQIUOaXSy1rkOXxf4ig8O9IOeN8YiIqI0YHUZWr16NZ599Fk899RS6deuGDRs2wMHBAbGxsfW+RqvV4vHHH8fSpUsRGhp6VwVT6zmUKPYX4SUaIiJqS0aFEbVajRMnTiA6Orp6B3I5oqOjcfTo0Xpf9+abb8LHxwczZ85s0vuUl5ejoKDAYKHWlV+iwZnUPADsvEpERG3LqDCSnZ0NrVYLX19fg/W+vr5IT0+v8zWHDx/Gxo0b8cknnzT5fVasWAFXV1f9EhzMW9i3tiNXs6ETgDBvRwS42UtdDhERWZFWHU1TWFiIJ598Ep988gm8vJr+1/aCBQuQn5+vX1JTU1uxSgKqL9FwCngiImprRs1q5eXlBYVCgYyMDIP1GRkZ8PPzq7X91atXcf36dYwfP16/TqfTiW9sY4OEhASEhYXVep1KpYJKpTKmNLoL4hTwYufVoZ14iYaIiNqWUS0jtra2iIyMRFxcnH6dTqdDXFwcBg4cWGv7Ll264OzZszh9+rR+efDBBzFixAicPn2al19MRHJOCW7crpwCvoOn1OUQEZGVMXq+77lz52L69Ono168fBgwYgDVr1qC4uBhPPfUUAGDatGkIDAzEihUrYGdnhx49ehi83s3NDQBqrSfpVF2i6dvOHY4qTgFPRERty+hPnilTpiArKwuLFi1Ceno6evfujV27duk7taakpEAu58Su5uSQ/hIN+4sQEVHbkwmCIEhdRGMKCgrg6uqK/Px8uLhwZtCWVKHVoc+be1FYXoEfZg1GRLCb1CUREZGFaOrnN5swrNyZG3koLK+Am4MSPQJdpS6HiIisEMOIlau6S+/gcC8oOAU8ERFJgGHEyh26UtlfhLOuEhGRRBhGrFh+qQZnbuQDAO7lZGdERCQRhhErdvRqDrQ6AaHejgjkFPBERCQRhhErVn2Jhq0iREQkHYYRK3boith59d5w9hchIiLpMIxYqeScYqTklsBGLsM9YZwCnoiIpMMwYqWqWkX6tneHE6eAJyIiCTGMWKmq/iJDeImGiIgkxjBihSq0Ohy5mgMAGML70RARkcQYRqzQmRv5KCyrgKu9Ej05BTwREUmMYcQKVV2iGRzuySngiYhIcgwjVuhwZefVIZxfhIiITADDiJUpKNPgVGoeAM4vQkREpoFhxMpUTQHfwcsRwR4OUpdDRETEMGJtqi/RsFWEiIhMA8OIldHPL8L+IkREZCIYRqxIam4JrueUQCGX4Z5QD6nLISIiAsAwYlX0U8C3c4OznVLiaoiIiEQMI1aEl2iIiMgUMYxYCa1OQHyi2DJyLzuvEhGRCWEYsRJ/3chDQVkFXOxs0ItTwBMRkQlhGLESVf1FBod7wUbB005ERKaDn0pWoqq/CC/REBGRqWEYsQKFZRqcSskDAAxl51UiIjIxDCNW4Ni1XFToBIR4OnAKeCIiMjkMI1aAl2iIiMiUMYxYger70fASDRERmR6GEQuXmluCa9nFUMhlGBjmKXU5REREtTCMWLjDlROd9Q52gwungCciIhPEMGLhqi/RsL8IERGZJoYRC6bVCfqWEfYXISIiU8UwYsHOpuUjv1QDZzsbRARxCngiIjJNDCMW7HDlkN5BYZ6cAp6IiEwWP6Es2G8c0ktERGaAYcRCFZVX4GTybQDsvEpERKaNYcRCHbuagwqdgHYeDmjv6Sh1OURERPViGLFQ1aNo2CpCRESmjWHEQv1W2XmV/UWIiMjUMYxYoLS8UlzLKoZcBk4BT0REJo9hxAJVDentHewGV3tOAU9ERKaNYcQCcUgvERGZE4YRC6PVCYhn51UiIjIjDCMW5vzNfOSVaOCsskFEsJvU5RARETWKYcTCHKq8RDMwzBNKTgFPRERmgJ9WFua3y1VDenmJhoiIzAPDiAUpLq/AyZSqKeDZeZWIiMwDw4gF+T0pBxqtgGAPe7T3dJC6HCIioiZhGLEgv10W+4vcG+4NmUwmcTVERERNwzBiQaruRzOU/UWIiMiMMIxYiJt5pUjMLIJcBgwKYxghIiLzwTBiIQ5XDuntFeQGVwdOAU9EROaDYcRCHOIlGiIiMlM2UhdAd0+nE/Q3xxvSiUN6zV52IpB8GHDvAPj1BBw8pK6IiKhVMYxYgPM3C3C7RAMnlQ16cwp483XrDHBoNXDhBwBC9XrXYMCvlxhM/HuJ/3cNAjhiiogsBMOIBTiUKLaK3BPKKeDNUvIR4NB7QOK+6nXBUUBRBnD7OpCfKi4JO6qft3cXw4lfZTjx7wV4dgQU/JEmIvPD31wW4FDl/CJDO7G/iNkQBODKXjGEpB4T18nkQI9JwL0vA77dxXVl+UD6OSD9L+DWX0D6WSDrIlB6G0j6TVyq2NgBPt0qW096An4R4n5sOQEeEZk2hhEzV6KuwJ/JuQCAe8MZRkyeTgtc+B449G8g46y4TmEL9H4cGPx/gEeo4fZ2rkDIYHGpUlEOZF2qDCeVASX9LKAuAm6eFJcqMjngGV7delIVUhw9W/1QiYiaimHEzP2elAuNVkCgmz06eDlKXQ7Vp0IN/LUVOLwGyL0qrrN1Avo9BdwzC3Dxb/q+bFSAf4S4VNHpgNtJNVpQKkNKUQaQfVlczn1Tvb2DF+DsBzj5Vi4+lY99Kh9X/l/l3HZ9U3Q6oDRXrLkwHSjKFP+vXzLF9WV5YqgKHwV0HCWGLfafITJrzQoj69atw7vvvov09HRERERg7dq1GDBgQJ3bfvLJJ9iyZQvOnTsHAIiMjMTy5cvr3Z6MU/MSDaeAN0HqYuDEZ8CRtUDhTXGdvTsQ9QIw4NmWGykjlwOeYeLS/aHq9YUZlS0nZ6ov8+ReBUqyxSXjXMP7tbEHnGsEFie/usOLo0/9/VXUJdVhwiBcZIj1VT1XnAnoKpp2vFf3i8vuBYBbeyA8WgwmHYYCtgzlRObG6DCybds2zJ07Fxs2bEBUVBTWrFmDmJgYJCQkwMfHp9b2Bw4cwNSpUzFo0CDY2dnhX//6F0aPHo3z588jMDCwRQ7Cmh2qHNJ7bziH9JqU0tvA8U+AY+vFv/YBwNkfGPQi0Hc6oHJqmzqcfcWlY3T1uvJCIDdJ/PCvGQaKarRGFGYA6kKgolTsRHv7eiNvJAMcPKuDilZTvb/yAuNqdvCqI/DUCD62DkDyUSBxr9j5Ny8Z+HOjuChsgfaDqltNvDqx1eRuCEJli9tZMczeTgLcQ6o7T7t3EIMw0V2SCYIgNL5ZtaioKPTv3x8ffvghAECn0yE4OBgvvvgiXnvttUZfr9Vq4e7ujg8//BDTpk1r0nsWFBTA1dUV+fn5cHFxMaZci5aeX4Z7VsRBJgNOLRwFNwdbqUuiwnTg6Drgz1ixDwcg/sK+92Ug4lHxEou5UBff0ZpReZmkVnjJBARtw/uysRODRF2Xgpx8q1tfHL0BhREzCJcXAdcPiZ2BE/cCeSmGz7u1E1tNwitbTdoqBJqjCjWQnVC7L1JDYdLWGfDrYdgnybsrYMPfRSRq6ue3US0jarUaJ06cwIIFC/Tr5HI5oqOjcfTo0Sbto6SkBBqNBh4e9TdPl5eXo7y8XP+4oMDIv6ysRFWrSK8gNwYRqeUmAUc+AE59AWgrv3d9e4ghpNtE8xxya+sIeHQQl4ZU9fWoGVRsbGv0R/Ftvb4nKieg81hxEQQg+4oYSq7sBZLjxXDyZ6y4KGyBdgPFFpPwUYB3Z+ttNSkvrB6lVdXPKOsSoFXX3lZhC/h0FQOHR2h1S0nGBbH1LOWouFSRKwGfLobDzn17AHb8Q5LqZ9RvyOzsbGi1Wvj6+hqs9/X1xaVLl5q0j/nz5yMgIADR0dH1brNixQosXbrUmNKs0qHK+9EM4Sga6WRcAA7/Gzj3v+rWgeAoYMgrQMfR1vFhJ5cDjl7igh7S1SGTAd6dxGXgLLFl5/rh6laT29eBpIPisucNcTI5fV+TYZbbalKYYRg60v8Ccq/Vva3KtcbkepWXYrw7191apdWIHaOrLuFUvUdZfnWrCr6o3t69g+GILr+eYkuZNfyMUKPa9M+1lStXYuvWrThw4ADs7Ozq3W7BggWYO3eu/nFBQQGCg4PbokSzodMJiK+8H80Q3o+m7d04Ic4RUnMisrCRYghpP4i/YE2BrSPQKUZcBAHIuVrdanL9sDiR3IlN4iJXAu0Hii0m4SMB7y6AXCH1ERin1oiqs+L/izLq3t45wDB0+PcSOwM39XtXoRTnsfHtLl6CBMSvc15K9WWeqpBSkCbWdjupcobhSo7ehrMLe3Y0v6+7nkycGZktQM1iVBjx8vKCQqFARobhN3dGRgb8/PwafO2qVauwcuVK7Nu3D7169WpwW5VKBZXKjK6tS+BsWj5yitVwtFWgTzt3qcuxHhVqYN9i4NhHlStkQLcHxcsxAX0kLY0aIJMBXuHics8L4gif64erw8ntpOpJ5PYuFEcR+Xav0UoQIV6qMJUJ5Oqca+aceNmkFhng1dEwdPj1qmzJamEyGeDeXly6jq9eX5xTo87KsJRzBSjOAq7GiYul8Ait8bWu0QJEDTIqjNja2iIyMhJxcXGYOHEiALEDa1xcHGbPnl3v69555x28/fbb2L17N/r163dXBZPo3/suAwBGdPGBrQ17s7eJvFTg6xlA2p/i44jHxBDi3UnSsqgZbB2ATqPFBRBbTaou5yQfBTTF4nmuOteAOIGcV6fa9wlq7RsZ1pyFt6q1IesSoNPU3lahAny7GYYO3+7SD3d29ATCRohLFXUJkHlBvCdTVUi5swOyOdFViKPocq+Ji0ELkM8drVARHIl0B6NH02zbtg3Tp0/Hxx9/jAEDBmDNmjXYvn07Ll26BF9fX0ybNg2BgYFYsWIFAOBf//oXFi1ahC+//BKDB1fPIunk5AQnp6Zdo+VoGkO/JmTiqU1/QKmQYc/LwzjZWVu4vAf47jnxl42dK/DQx2KnSbI8Oq34YVKzj8Wtv8R5WeriElT7codrsPGX6gRB7ARsMHHdX/UPq7ZzqwxFEdUByauTeXaWthTF2bUvUWVfgcGNL6vYOokde2sGW5+u5jXirglaZTQNAEyZMgVZWVlYtGgR0tPT0bt3b+zatUvfqTUlJQXyGmlv/fr1UKvVePjhhw32s3jxYixZssTYt7d6Gq0Ob/18AQAwY1AIg0hr01YAv74NHF4tPg7oAzzymdgMTZZJrhAva3h1FO8VBBgGhZph4fZ1oOCGuCTsrN6HQVCoDCk1g4JOJ04+V7NVoEmBp0arTHMCD7UuRy8g7D5xqaIuFju6p5+pDimZF8Sh/6nHqu9NBQByG7G/kkHrW0/xDyALZ3TLiBTYMlJtU3wSlv50AR6Otvh13nC42hsxJwMZpzAd+GYmkHxYfDzgOWD0Wxb3lwvdhTovoVyseybZqksociWQcV68FHQnqS4FUdvSVoh9Zmq2gN36S7zVQV3c2ovfDy4B1cPlDWZA9jbZjr9N/fxmGDEjt4vVGL7qAPJLNXj7oR54PIp/nbeapN/EIFKcKTanPvhB9V/JRA1p6EaGNZl6J1lqW4IA5N+oPRoqP7Xx18rk1TMX17p9g49heFE5t/6x1NBql2lIOmv2XUZ+qQZd/JzxaP92UpdjmXQ64PB7wK/LAUEH+HQHJm8RR2EQNUVjNzLUVogBxDOc/TuomkwGuAWLS5f7q9eX5IrBJOvSHTeQrPx/cZb4u6q48v5OVXcDr4/SsfbMx1XBpeMoyUb+8CfBTFzOKMTnv4s9zRc90A0KOa8Vt7jiHLGTauI+8XHvJ4Bx7/IvVbp7NW9kSGQMBw8gdJi41EWnFTvONnQTyqrgoi4SLw9Wzflyp6d2MYxQ/QRBwLKfL0CrEzC6my8GccbVlpd6XBy2W5AmNp/fvwro84TUVRERNUyuqL4hZmPKixq+g7ZrUOvXWw+GETPwa0ImDl3JhlIhw+v3d5W6HMsiCOIEZnsXiZ0OPcPFyzK+3aWujIioZamcxMUEW+gYRkycukKHt36+CAB4enAHtPfkUN4WU5YP/DALuPiT+Lj738SOqm3cwYuIyNoxjJi4LUev41p2MbycbDH7PnaibDG3zgDbp4nzRMiVwJgVQP9nOG8DEZEEGEZMWG6xGu/HXQEAzBvdGc52nFPkrgmCeGO0X14DtOWAWzvgkc1AYKTUlRERWS2GERO2em8CCssq0NXfBY/0412L71p5EfDzy8DZ7eLjTmOBh9YD9rzRIBGRlBhGTNSl9AJ8WTmUd/F4DuW9a5mXxMsy2QmATAFELwYG/R8vyxARmQCGERNUNZRXJwBje/jhnlBPqUsyb2e2AT/PATQlgLM/8HAs0H6Q1FUREVElhhETtO9iJuITc2CrkOOf4ziUt9k0ZcCu+cCJzeLj0OHA3z4FnLylrIqIiO7AMGJiyiu0eHuHeFfemUM6INiDs382S85V4Ovp4jTKkAHDXwOGvmqyN5MiIrJmDCMmZsuRZFzPKYG3swqzRnAor9EEATj5GbD7DUBdCDh4ApM+NbylNxERmRSGEROSXVSODyqH8r4a0xlOKp4eo+SlAD++CFw7ID5uNwh4eKN4220iIjJZ/LQzIe/tuYzC8gr0CHTBw32lu0eA2amaO2TPQvFGUDZ2wMhFQNTzvCxDRGQGGEZMxIWbBdj2R9VdebtDzqG8TXNna0jwPcDEj0zy3gtERFQ3hhETUHMo7/29/DGgg4fUJZk+QQD+jBVvcKcuEu+0O3IREPV3toYQEZkZhhETsOdCBo5ey4GtjRyvjekidTmm73Yy8ONsIOk38XG7gcCEdWwNISIyUwwjEiuv0GL5TvGuvM8NCeVQ3obodMCJWGDPIkBTLLaGRC8GBvwdkMulro6IiJqJYURim+KvIzmnBD7OKrwwnH/Z1+v2deCH2cD1Q+LjdoOACR+yNYSIyAIwjEgoq7AcH+5PBAD8vzFd4MihvLXpdMCfG4G9i8XWEKUDEL0E6P8sW0OIiCwEP/0k9N6eBBSVVyAiyBV/6xModTmm587WkPaDxdYQj1BJyyIiopbFMCKRc2n52PZnKgBg0fhuHMpbU52tIUuB/s+wNYSIyAIxjEigaiivIADjIwIQ2Z5DefVyk8TWkOTD4uP291a2hnSQti4iImo1DCMS2HUuHb8n5cJOKcdrYzmUF4DYGvLHp8C+xYCmBFA6AqOWAv1msjWEiMjCMYy0sTKNFm9XDeUdGoZAN/vm7Sg/TbyUoasAnHzvWHwAO1dAZiaXfnKvVbaGxIuPQ4YAD65lawgRkZVgGGljsfFJuHG7FH4udnh+WDM6YqpLgCMfAPHviy0I9bGxE0PJnUHFuUZgcfIFHH0AG9vmH9Dd0OmAPz4B9i2pbg0Z/SYQ+TRbQ4iIrAjDSBvKLCjDusqhvPPHdoaDrRFffp0OOPeN+MFdkCauC74HCIwEijIMl7J8oKJMvG9LXkrj+7b3qCOo+AGOXoC8lb5FBB1wYrNha8iEDwH3kNZ5PyIiMlkMI23o3d0JKFZr0TvYDRMijBjKm/oHsOs1IO1P8bFrO7E/RfeH6r4UoykFijIrl/TKkJIJFKZXrqsRXHQVQGmuuGRdbJkDNQZbQ4iIrB7DSBs5eyMf35y8AcCIobz5N8SWkLNfi4+VjsCQucDAWYCygb4mSnvAvb24NESnA8ryKkNKzdaVyuBSkiO2YLQWlwBg+ILG6yQiIovGMNIGBEHAmz+fhyAAE3sHoG8794ZfoC4W+4TEfwBUlAKQAX0eB+5bCDj7tVxhcjng4CEuvt1abr9ERERGYBhpAzvO3sIf12/DXqnA/IaG8up0wNntYmtI4S1xXbtBwJgVQEDvtiiViIiozTGMtLIyjRYrdl4CADw/LAz+rvVcXkn5XewXcvOk+NitHTD6LaDrg+YzRJeIiKgZGEZa2aeHriEtrxQBrnZ4bmgdQ3nzUsSWkHP/Ex/bOgFD5wFRLwBKuzatlYiISAoMI60oo6AMHx24CgCYP7YL7G0V1U+WFwHxa4Aja8VhuJABfZ8ERrwhDrElIiKyEgwjreRWfimW/HgeJWot+rZzw4MRAeITOh3w11Zg31Jx2C0g3n9lzArAv5d0BRMREUmEYaQFpeSU4Jdzt/DLuXScTs3Tr188vjtkMhmQfFTsF3LrtPiEe4jYL6TLA+wXQkREVoth5C4lZhZhV2UAOX+zQL9eJgP6tXfHU4M7IMIpH/h6DnD+O/FJW2dg2KtA1POAjUqawomIiEwEw4iRBEHApfRC/HJWDCBXMov0zynkMtwT6oExPfwR080XPioNcPjfwPcfAtpyQCYH+k4DRrwuTrlOREREDCNNIQgC/rqRj1/OpWPXuVu4nlN9gzqlQobB4V4Y39kJozwy4ZJ3GkjfApz6C8i6BOg04oYhQ8R+IX49pTkIIiIiE8UwUg+dTsDJlNvYeTYdu8+nIy2vtPIZAcE2+ZgcdBv3uWWgky4JyqyzwJ7rde/IIwwYvQzoPI79QoiIiOrAMFJDhVaH40m5+OWcGECyCkvRQZaOPrJkzFClYLBjGsK0SVCV5wDpEJeaXILEETF+PQG/yn/d2jGEEBERNcDqw4i6Qof4q9nYdyYZ1y+dQFB5IrrLrmOCPBnd7JLhgPLqjauuzsjkgFen6tDh3wvw7Qk4ekpyDERERObMasOIIAj47j9vQnHrT3TSJWGJ7CaUMi2gvGNDG3vAt7sYPPx7ieHDpxtg6yBJ3URERJbGasOITCZDRPbPCMNlQC6u09i6QREYAbl/L8AvQgwgnuGAwmq/TERERK3Oqj9lFZFPIq0sF/6d+0MeEAGlSyD7dxAREbUxqw4jIWP+T+oSiIiIrJ5c6gKIiIjIujGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpKUWdy1VxAEAEBBQYHElRAREVFTVX1uV32O18cswkhhYSEAIDg4WOJKiIiIyFiFhYVwdXWt93mZ0FhcMQE6nQ43b96Es7MzZDJZi+23oKAAwcHBSE1NhYuLS4vt11RZ0/HyWC2XNR0vj9VyWcvxCoKAwsJCBAQEQC6vv2eIWbSMyOVyBAUFtdr+XVxcLPqb4U7WdLw8VstlTcfLY7Vc1nC8DbWIVGEHViIiIpIUwwgRERFJyqrDiEqlwuLFi6FSqaQupU1Y0/HyWC2XNR0vj9VyWdvxNsYsOrASERGR5bLqlhEiIiKSHsMIERERSYphhIiIiCTFMEJERESSsvgwsm7dOoSEhMDOzg5RUVE4fvx4g9t//fXX6NKlC+zs7NCzZ0/s3LmzjSq9OytWrED//v3h7OwMHx8fTJw4EQkJCQ2+ZvPmzZDJZAaLnZ1dG1XcfEuWLKlVd5cuXRp8jbme15CQkFrHKpPJMGvWrDq3N7dz+ttvv2H8+PEICAiATCbD999/b/C8IAhYtGgR/P39YW9vj+joaFy5cqXR/Rr7c98WGjpWjUaD+fPno2fPnnB0dERAQACmTZuGmzdvNrjP5vwstIXGzuuMGTNq1T1mzJhG92uK5xVo/Hjr+hmWyWR49913692nqZ7b1mLRYWTbtm2YO3cuFi9ejJMnTyIiIgIxMTHIzMysc/sjR45g6tSpmDlzJk6dOoWJEydi4sSJOHfuXBtXbryDBw9i1qxZOHbsGPbu3QuNRoPRo0ejuLi4wde5uLjg1q1b+iU5ObmNKr473bt3N6j78OHD9W5rzuf1jz/+MDjOvXv3AgAeeeSRel9jTue0uLgYERERWLduXZ3Pv/POO/jggw+wYcMG/P7773B0dERMTAzKysrq3aexP/dtpaFjLSkpwcmTJ7Fw4UKcPHkS3377LRISEvDggw82ul9jfhbaSmPnFQDGjBljUPdXX33V4D5N9bwCjR9vzeO8desWYmNjIZPJMGnSpAb3a4rnttUIFmzAgAHCrFmz9I+1Wq0QEBAgrFixos7tJ0+eLNx///0G66KiooS///3vrVpna8jMzBQACAcPHqx3m02bNgmurq5tV1QLWbx4sRAREdHk7S3pvL700ktCWFiYoNPp6nzeXM+pIAgCAOG7777TP9bpdIKfn5/w7rvv6tfl5eUJKpVK+Oqrr+rdj7E/91K481jrcvz4cQGAkJycXO82xv4sSKGuY50+fbowYcIEo/ZjDudVEJp2bidMmCDcd999DW5jDue2JVlsy4harcaJEycQHR2tXyeXyxEdHY2jR4/W+ZqjR48abA8AMTEx9W5vyvLz8wEAHh4eDW5XVFSE9u3bIzg4GBMmTMD58+fbory7duXKFQQEBCA0NBSPP/44UlJS6t3WUs6rWq3G559/jqeffrrBG0aa6zm9U1JSEtLT0w3OnaurK6Kiouo9d835uTdV+fn5kMlkcHNza3A7Y34WTMmBAwfg4+ODzp0744UXXkBOTk6921rSec3IyMCOHTswc+bMRrc113PbHBYbRrKzs6HVauHr62uw3tfXF+np6XW+Jj093ajtTZVOp8OcOXMwePBg9OjRo97tOnfujNjYWPzwww/4/PPPodPpMGjQINy4caMNqzVeVFQUNm/ejF27dmH9+vVISkrCkCFDUFhYWOf2lnJev//+e+Tl5WHGjBn1bmOu57QuVefHmHPXnJ97U1RWVob58+dj6tSpDd5EzdifBVMxZswYbNmyBXFxcfjXv/6FgwcPYuzYsdBqtXVubynnFQA+++wzODs7429/+1uD25nruW0us7hrLxln1qxZOHfuXKPXFwcOHIiBAwfqHw8aNAhdu3bFxx9/jGXLlrV2mc02duxY/f979eqFqKgotG/fHtu3b2/SXxvmauPGjRg7diwCAgLq3cZczylV02g0mDx5MgRBwPr16xvc1lx/Fh599FH9/3v27IlevXohLCwMBw4cwMiRIyWsrPXFxsbi8ccfb7Rjubme2+ay2JYRLy8vKBQKZGRkGKzPyMiAn59fna/x8/MzantTNHv2bPz888/49ddfERQUZNRrlUol+vTpg8TExFaqrnW4ubmhU6dO9dZtCec1OTkZ+/btwzPPPGPU68z1nALQnx9jzl1zfu5NSVUQSU5Oxt69e42+tXxjPwumKjQ0FF5eXvXWbe7ntcqhQ4eQkJBg9M8xYL7ntqksNozY2toiMjIScXFx+nU6nQ5xcXEGfznWNHDgQIPtAWDv3r31bm9KBEHA7Nmz8d1332H//v3o0KGD0fvQarU4e/Ys/P39W6HC1lNUVISrV6/WW7c5n9cqmzZtgo+PD+6//36jXmeu5xQAOnToAD8/P4NzV1BQgN9//73ec9ecn3tTURVErly5gn379sHT09PofTT2s2Cqbty4gZycnHrrNufzWtPGjRsRGRmJiIgIo19rrue2yaTuQduatm7dKqhUKmHz5s3ChQsXhOeee05wc3MT0tPTBUEQhCeffFJ47bXX9NvHx8cLNjY2wqpVq4SLFy8KixcvFpRKpXD27FmpDqHJXnjhBcHV1VU4cOCAcOvWLf1SUlKi3+bO4126dKmwe/du4erVq8KJEyeERx99VLCzsxPOnz8vxSE02SuvvCIcOHBASEpKEuLj44Xo6GjBy8tLyMzMFATBss6rIIijBtq1ayfMnz+/1nPmfk4LCwuFU6dOCadOnRIACKtXrxZOnTqlH0GycuVKwc3NTfjhhx+Ev/76S5gwYYLQoUMHobS0VL+P++67T1i7dq3+cWM/91Jp6FjVarXw4IMPCkFBQcLp06cNfobLy8v1+7jzWBv7WZBKQ8daWFgozJs3Tzh69KiQlJQk7Nu3T+jbt6/QsWNHoaysTL8PczmvgtD497EgCEJ+fr7g4OAgrF+/vs59mMu5bS0WHUYEQRDWrl0rtGvXTrC1tRUGDBggHDt2TP/csGHDhOnTpxtsv337dqFTp06Cra2t0L17d2HHjh1tXHHzAKhz2bRpk36bO493zpw5+q+Nr6+vMG7cOOHkyZNtX7yRpkyZIvj7+wu2trZCYGCgMGXKFCExMVH/vCWdV0EQhN27dwsAhISEhFrPmfs5/fXXX+v8vq06Jp1OJyxcuFDw9fUVVCqVMHLkyFpfh/bt2wuLFy82WNfQz71UGjrWpKSken+Gf/31V/0+7jzWxn4WpNLQsZaUlAijR48WvL29BaVSKbRv31549tlna4UKczmvgtD497EgCMLHH38s2NvbC3l5eXXuw1zObWuRCYIgtGrTCxEREVEDLLbPCBEREZkHhhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgk9f8B9P/Ik6pAbTIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.summary();\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.1490 - loss: 6.2671\n",
      "Test Loss: 6.066964626312256\n",
      "Test Accuracy: 0.16455696523189545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "Predicted: [ 6  7  0  2  9 13  2  5 12 12  0 15 18  7  7 15 12 15 12 12  7  0 19  3\n",
      "  7  7 11  0 16 12  9 10]\n",
      "Actual: [20 14 16  9 17 17 14  0 15 10 16  7 14 14 18 19  7 13  7 19 15  0  8  3\n",
      " 12 15  5  2  2 14  1 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 08:37:07.135268: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_ds.take(1):  # Take one batch from the test dataset\n",
    "    predictions = model.predict(images)\n",
    "    predicted_classes = tf.argmax(predictions, axis=1)\n",
    "    print(\"Predicted:\", predicted_classes.numpy())\n",
    "    print(\"Actual:\", labels.numpy())\n",
    "\n",
    "\n",
    "# featuremap = model.predict(test_ds)\n",
    "\n",
    "# # Plot the feature map\n",
    "# plt.imshow(featuremap[ 21, 0])  # Display the first feature map\n",
    "# plt.show()\n",
    "\n",
    "# print(featuremap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.1720 - val_loss: 5.9211 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.1783 - val_loss: 5.9406 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.1783 - val_loss: 5.9609 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.1720 - val_loss: 5.9764 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.1847 - val_loss: 5.9875 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.1720 - val_loss: 6.0117 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.1847 - val_loss: 6.0154 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.1847 - val_loss: 6.0263 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.1847 - val_loss: 6.0332 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.1847 - val_loss: 6.0420 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "# y_pred= model.predict(test_ds)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "\n",
    "# def compute_confusion_matrix(true, pred):\n",
    "#     k = len(np.unique(true)) #Number of classes\n",
    "#     result = np.zeros([k, k])\n",
    "#     for i in range(len(true)):\n",
    "#         result[true[i]][pred[i]] += 1\n",
    "#     return result\n",
    "\n",
    "# # print(y_pred.shape)\n",
    "# # print(y_pred_t)\n",
    "\n",
    "\n",
    "# confusion_mx = compute_confusion_matrix(test_labels, y_pred)\n",
    "# print(confusion_mx)\n",
    "# diagonal_predictions = np.trace(confusion_mx)\n",
    "# # print(diagonal_predictions)\n",
    "# # print(len(y_test))\n",
    "# Accuracy = ((diagonal_predictions)/len(test_labels))*100\n",
    "# print(\"Accuracy:\", Accuracy, \"%\")\n",
    "history_2 = model.fit(train_ds, \n",
    "                    validation_data=val_ds, \n",
    "                    epochs=30, \n",
    "                    initial_epoch=20,  # Start from epoch 20\n",
    "                    callbacks=[lr_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.1847 - val_loss: 6.0495 - learning_rate: 6.2500e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.1847 - val_loss: 6.0565 - learning_rate: 6.2500e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.1847 - val_loss: 6.0647 - learning_rate: 6.2500e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.1847 - val_loss: 6.0728 - learning_rate: 6.2500e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.9702e-04 - val_accuracy: 0.1847 - val_loss: 6.0781 - learning_rate: 6.2500e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.7559e-04\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.7244e-04 - val_accuracy: 0.1847 - val_loss: 6.0866 - learning_rate: 6.2500e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.4642e-04 - val_accuracy: 0.1847 - val_loss: 6.0893 - learning_rate: 3.1250e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.3485e-04 - val_accuracy: 0.1847 - val_loss: 6.0933 - learning_rate: 3.1250e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.2321e-04 - val_accuracy: 0.1847 - val_loss: 6.0977 - learning_rate: 3.1250e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.1126e-04 - val_accuracy: 0.1847 - val_loss: 6.1015 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history_3 = model.fit(train_ds, \n",
    "                    validation_data=val_ds, \n",
    "                    epochs=40, \n",
    "                    initial_epoch=30,  # Start from epoch 20\n",
    "                    callbacks=[lr_callback])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
